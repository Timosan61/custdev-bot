# Новая логика работы ResearcherAgent

## Изменения в системе

### 1. Статичные вопросы
Теперь все вопросы исследователю заранее определены и не генерируются LLM:

- **name**: "Как к вам обращаться?"
- **industry**: "В какой сфере, нише или контексте проводится исследование?"
- **target**: "Кого / что вы планируете изучать? Опишите, пожалуйста..."
- **hypotheses**: "Какие рабочие гипотезы или предположения хотите проверить?..."
- **style**: "В каком тоне общаться с респондентами?..."
- **success_metric**: "По каким метрикам вы поймёте, что исследование успешно?" (необязательное)
- **constraints**: "Есть ли ограничения: время интервью, темы-табу..." (необязательное)
- **existing_data**: "Есть ли уже собранные данные/аналитика..." (необязательное)

### 2. Механизм оценки качества ответов
- После каждого ответа LLM проверяет его качество через `field_analyzer.txt`
- Если ответ неполный или неясный, генерируется уточняющий вопрос
- После одной попытки уточнения ответ принимается в любом случае

### 3. Интервью-бриф
После сбора всех полей генерируется структурированный документ:
- Сводка проекта с всеми параметрами
- План интервью
- Первое сообщение для респондентов

### 4. Промпты в файлах
Все промпты теперь хранятся в папке `src/prompts/`:
- `field_analyzer.txt` - оценка качества ответов
- `clarification_generator.txt` - генерация уточняющих вопросов
- `interview_brief_generator.txt` - создание интервью-брифа
- `instruction_generator.txt` - генерация инструкции для интервью
- `first_question_generator.txt` - первый вопрос респонденту
- `next_question_generator.txt` - последующие вопросы респонденту
- `interview_summary_generator.txt` - резюме интервью

## Преимущества новой системы
1. Предсказуемое поведение бота
2. Стандартизированный процесс сбора данных
3. Возможность пропуска необязательных полей
4. Структурированный вывод в виде интервью-брифа
5. Легкая модификация промптов без изменения кода