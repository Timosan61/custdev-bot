from typing import Dict, Optional
from aiogram import types, Bot
from aiogram.fsm.context import FSMContext
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from loguru import logger
import json
import re
import os

from src.services.supabase_service import SupabaseService
from src.services.zep_service import ZepService
from src.services.voice_handler import VoiceMessageHandler
from src.utils.keyboards import get_cancel_keyboard
from src.state.user_states import ResearcherStates

class ResearcherAgent:
    def __init__(self, supabase: SupabaseService, zep: ZepService):
        self.supabase = supabase
        self.zep = zep
        # Initialize voice handler with bot token
        bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
        self.voice_handler = VoiceMessageHandler(bot_token=bot_token)
        self.llm = ChatOpenAI(model_name="gpt-4o", temperature=0.7)
        
        # –°—Ç–∞—Ç–∏—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –ø–æ–ª—è
        self.static_questions = {
            "name": "–ö–∞–∫ –∫ –≤–∞–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è?",
            "industry": "–í –∫–∞–∫–æ–π —Å—Ñ–µ—Ä–µ, –Ω–∏—à–µ –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ?",
            "target": "–ö–æ–≥–æ / —á—Ç–æ –≤—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –∏–∑—É—á–∞—Ç—å? –û–ø–∏—à–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞:\n1) –µ—Å–ª–∏ —ç—Ç–æ –ª—é–¥–∏ ‚Äî —Å–µ–≥–º–µ–Ω—Ç, —Ä–æ–ª—å, –≤–æ–∑—Ä–∞—Å—Ç, –≥–µ–æ–≥—Ä–∞—Ñ–∏—é;\n2) –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å—ã –∏–ª–∏ –ø—Ä–æ–¥—É–∫—Ç ‚Äî –µ–≥–æ —ç—Ç–∞–ø—ã/—Ñ—É–Ω–∫—Ü–∏–∏, –≥–¥–µ ¬´–±–æ–ª–∏—Ç¬ª.",
            "hypotheses": "–ö–∞–∫–∏–µ —Ä–∞–±–æ—á–∏–µ –≥–∏–ø–æ—Ç–µ–∑—ã –∏–ª–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å? –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ ¬´–µ—Å–ª–∏ ‚Ä¶ —Ç–æ ‚Ä¶ ‚Üí –æ–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç¬ª.",
            "style": "–í –∫–∞–∫–æ–º —Ç–æ–Ω–µ –æ–±—â–∞—Ç—å—Å—è —Å —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞–º–∏? –í—ã–±–µ—Ä–∏—Ç–µ –∏–ª–∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Å–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç:\n‚Ä¢ –î—Ä—É–∂–µ–ª—é–±–Ω–æ, –Ω–∞ ¬´—Ç—ã¬ª\n‚Ä¢ –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π, –Ω–∞ ¬´–≤—ã¬ª\n‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç‚Äì—ç–∫—Å–ø–µ—Ä—Ç (—Ç–µ—Ä–º–∏–Ω—ã –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è)\n‚Ä¢ –õ–∞–π—Ç–æ–≤–æ —Å —é–º–æ—Ä–æ–º",
            "success_metric": "–ü–æ –∫–∞–∫–∏–º –º–µ—Ç—Ä–∏–∫–∞–º –≤—ã –ø–æ–π–º—ë—Ç–µ, —á—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ?\n–ù–∞–ø—Ä.: ¬´–Ω–∞–π—Ç–∏ 3 –∫–ª—é—á–µ–≤—ã–µ –º–æ—Ç–∏–≤–∞—Ü–∏–∏¬ª, ¬´–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å/–æ–ø—Ä–æ–≤–µ—Ä–≥–Ω—É—Ç—å 2 –≥–∏–ø–æ—Ç–µ–∑—ã¬ª.",
            "constraints": "–ï—Å—Ç—å –ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: –≤—Ä–µ–º—è –∏–Ω—Ç–µ—Ä–≤—å—é, —Ç–µ–º—ã-—Ç–∞–±—É, —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (NDA/GDPR)?",
            "existing_data": "–ï—Å—Ç—å –ª–∏ —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–∞–Ω–∞–ª–∏—Ç–∏–∫–∞, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ–∏—Ç –æ–ø–∏—Ä–∞—Ç—å—Å—è?\n–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª (PDF, txt, docx) –∏–ª–∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ."
        }
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        self.required_fields = ["name", "industry", "target", "hypotheses", "style"]
        self.optional_fields = ["success_metric", "constraints", "existing_data"]
        
        # –ü–æ—Ä—è–¥–æ–∫ –∑–∞–¥–∞–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
        self.question_order = self.required_fields + self.optional_fields
        
        # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.fields_to_collect = self.static_questions
    
    async def start_dialog(self, message: types.Message, state: FSMContext):
        user_id = message.from_user.id
        
        # Create new interview
        interview = self.supabase.create_interview({"researcher_telegram_id": user_id})
        if not interview:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é")
            return
        interview_id = interview["id"]
        
        # Create Zep session
        zep_session_id = f"researcher_{user_id}_{interview_id}"
        await self.zep.create_session(zep_session_id, {
            "user_id": user_id,
            "interview_id": interview_id,
            "type": "researcher"
        })
        
        # Save to state
        await state.update_data(
            interview_id=interview_id,
            zep_session_id=zep_session_id,
            collected_fields={}
        )
        
        # Send welcome message and first question
        welcome_text = (
            "üî¨ <b>–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è</b>\n\n"
            "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É –≤–∞–º —Å–æ–∑–¥–∞—Ç—å –∫–∞—Å—Ç–¥–µ–≤-–∏–Ω—Ç–µ—Ä–≤—å—é.\n\n"
            "–û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –º–æ–∏ –≤–æ–ø—Ä–æ—Å—ã –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥–æ–ª–æ—Å–æ–º. "
            "–ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ, —Å–∫–∞–∂–∏—Ç–µ '—Ö–≤–∞—Ç–∏—Ç' –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è."
        )
        
        await message.answer(welcome_text, reply_markup=types.ReplyKeyboardRemove())
        
        # Ask first question from static questions
        first_field = self.question_order[0]
        first_question = self.static_questions[first_field]
        await message.answer(first_question)
        
        # Track current field index
        await state.update_data(current_field_index=0)
        
        # Save first question in state
        await state.update_data(last_question=first_question)
        
        # Log to Zep
        await self.zep.add_message(zep_session_id, "assistant", welcome_text)
        await self.zep.add_message(zep_session_id, "assistant", first_question)
    
    async def process_text_message(self, message: types.Message, state: FSMContext):
        await self._process_message(message.text, message, state)
    
    async def process_voice_message(self, message: types.Message, state: FSMContext, bot: Bot):
        # Send processing indicator
        processing_msg = await message.answer("üé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        
        # Process voice message
        result = await self.voice_handler.process_voice_message(
            file_id=message.voice.file_id,
            duration=message.voice.duration
        )
        
        # Delete processing message
        await bot.delete_message(message.chat.id, processing_msg.message_id)
        
        if result["success"]:
            text = result["transcription"]
            logger.info(f"Voice transcribed: {text}")
            
            # Process the message
            await self._process_message(text, message, state)
        else:
            error = result.get("error", "Unknown error")
            logger.error(f"Voice processing failed: {error}")
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–º.")
    
    async def _process_message(self, text: str, message: types.Message, state: FSMContext):
        data = await state.get_data()
        user_id = message.from_user.id
        interview_id = data.get("interview_id")
        zep_session_id = data.get("zep_session_id")
        collected_fields = data.get("collected_fields", {})
        current_field_index = data.get("current_field_index", 0)
        current_field = self.question_order[current_field_index] if current_field_index < len(self.question_order) else None
        is_clarification = data.get("is_clarification", False)
        
        logger.info(f"Processing message from user {user_id}: {text[:50]}...")
        logger.debug(f"Current field: {current_field}, Index: {current_field_index}")
        logger.debug(f"Is clarification: {is_clarification}")
        
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        if current_field in self.required_fields:
            text_lower = text.lower().strip()
            # –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –¥–ª—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            stop_words = ["–Ω–µ –∑–Ω–∞—é", "–Ω–µ–∑–Ω–∞—é", "–Ω–µ –ø–æ–Ω–∏–º–∞—é", "—Ö–∑", "—Ñ–∏–≥ –∑–Ω–∞–µ—Ç", "–ø–æ–Ω—è—Ç–∏—è –Ω–µ –∏–º–µ—é"]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
            if any(stop_word in text_lower for stop_word in stop_words):
                logger.warning(f"Stop word detected in answer for {current_field}: {text}")
                await message.answer(
                    f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–∞–π—Ç–µ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç. "
                    f"–≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω—Ç–µ—Ä–≤—å—é –ø–æ–¥ –≤–∞—à–∏ –∑–∞–¥–∞—á–∏."
                )
                return
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–ª–µ–π
            min_lengths = {
                "industry": 5,
                "target": 10,
                "hypotheses": 15,
                "style": 5
            }
            
            if current_field in min_lengths and len(text.strip()) < min_lengths[current_field]:
                logger.warning(f"Answer too short for {current_field}: {len(text)} chars")
                await message.answer(
                    f"–í–∞—à –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ."
                )
                return
        
        # Log user message to Zep
        await self.zep.add_message(zep_session_id, "user", text)
        
        # Check if user wants to finish
        if any(word in text.lower() for word in ["—Ö–≤–∞—Ç–∏—Ç", "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ", "–≤—Å–µ", "—Å—Ç–æ–ø"]):
            # Check if we have all required fields
            missing_required = [f for f in self.required_fields if f not in collected_fields]
            if missing_required:
                await message.answer(
                    f"‚ùó –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.\n"
                    f"–û—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–æ–ª–Ω–∏—Ç—å: {', '.join([self.static_questions[f][:30] + '...' for f in missing_required[:2]])}\n\n"
                    f"–•–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å?"
                )
                return
            else:
                await self._finish_collection(message, state)
                return
        
        # Extract answer for current field
        if current_field:
            # Use field analyzer to check answer quality
            quality_result = await self._evaluate_answer_quality(current_field, text)
            
            logger.info(f"Quality evaluation for {current_field}: {quality_result}")
            
            if quality_result["is_complete"]:
                # Save the answer
                collected_fields[current_field] = quality_result["extracted_value"]
                await state.update_data(collected_fields=collected_fields, is_clarification=False)
                logger.info(f"Field {current_field} saved: {quality_result['extracted_value']}")
                
                # Move to next field
                next_index = current_field_index + 1
                
                # Skip optional fields if user said "no" or "skip"
                while next_index < len(self.question_order):
                    next_field = self.question_order[next_index]
                    if next_field in self.optional_fields and any(word in text.lower() for word in ["–Ω–µ—Ç", "–Ω–µ –Ω–∞–¥–æ", "–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å", "skip"]):
                        logger.info(f"Skipping optional field: {next_field}")
                        next_index += 1
                    else:
                        break
                
                if next_index < len(self.question_order):
                    # Ask next static question
                    next_field = self.question_order[next_index]
                    next_question = self.static_questions[next_field]
                    await message.answer(next_question)
                    await self.zep.add_message(zep_session_id, "assistant", next_question)
                    await state.update_data(current_field_index=next_index, last_question=next_question)
                else:
                    # All questions asked
                    await self._finish_collection(message, state)
            else:
                # Need clarification
                if is_clarification:
                    # This was already a clarification attempt, accept the answer anyway
                    collected_fields[current_field] = text
                    await state.update_data(collected_fields=collected_fields, is_clarification=False)
                    
                    # Move to next field
                    next_index = current_field_index + 1
                    if next_index < len(self.question_order):
                        next_field = self.question_order[next_index]
                        next_question = self.static_questions[next_field]
                        await message.answer(next_question)
                        await self.zep.add_message(zep_session_id, "assistant", next_question)
                        await state.update_data(current_field_index=next_index, last_question=next_question)
                    else:
                        await self._finish_collection(message, state)
                else:
                    # Generate clarification question
                    clarification = await self._generate_clarification(
                        current_field,
                        text,
                        quality_result["missing_aspects"]
                    )
                    await message.answer(clarification)
                    await self.zep.add_message(zep_session_id, "assistant", clarification)
                    await state.update_data(is_clarification=True, last_question=clarification)
    
    async def _evaluate_answer_quality(self, field: str, answer: str) -> Dict:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å"""
        with open("src/prompts/field_analyzer.txt", "r") as f:
            template = f.read()
        
        prompt = PromptTemplate(
            input_variables=["field_name", "field_description", "question", "answer"],
            template=template
        )
        
        field_description = {
            "name": "–ò–º—è –∏–ª–∏ –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—é",
            "industry": "–°—Ñ–µ—Ä–∞ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–ª–∏ –Ω–∏—à–∞ –±–∏–∑–Ω–µ—Å–∞",
            "target": "–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è –∏–ª–∏ –æ–±—ä–µ–∫—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏",
            "hypotheses": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –µ—Å–ª–∏...—Ç–æ...",
            "style": "–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è —Å —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞–º–∏",
            "success_metric": "–ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
            "constraints": "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏, —Ç–µ–º–∞–º –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è",
            "existing_data": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö"
        }
        
        try:
            response = await self.llm.ainvoke(
                prompt.format(
                    field_name=field,
                    field_description=field_description.get(field, ""),
                    question=self.static_questions.get(field, ""),
                    answer=answer
                )
            )
            
            # Parse JSON response
            content = response.content.strip()
            logger.debug(f"LLM response for {field}: {content[:200]}...")
            
            if content.startswith("```json") and content.endswith("```"):
                content = content[7:-3].strip()
            elif content.startswith("```") and content.endswith("```"):
                content = content[3:-3].strip()
            
            result = json.loads(content)
            logger.debug(f"Parsed result for {field}: {result}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error in evaluate_answer_quality: {e}")
            logger.error(f"Response content: {content[:200]}...")
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ–º –æ—Ç–≤–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            return {
                "is_complete": False,
                "confidence": 0.0,
                "missing_aspects": ["–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç"],
                "extracted_value": None
            }
        except Exception as e:
            logger.error(f"Error evaluating answer quality: {e}", exc_info=True)
            # –ü—Ä–∏ –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–∫–∞—Ö —Ç–æ–∂–µ –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ–º –æ—Ç–≤–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            return {
                "is_complete": False,
                "confidence": 0.0,
                "missing_aspects": ["–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ"],
                "extracted_value": None
            }
    
    async def _generate_clarification(self, field: str, answer: str, missing_aspects: list) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å"""
        with open("src/prompts/clarification_generator.txt", "r") as f:
            template = f.read()
        
        prompt = PromptTemplate(
            input_variables=["field_name", "original_question", "answer", "missing_aspects", "conversation_history"],
            template=template
        )
        
        response = await self.llm.ainvoke(
            prompt.format(
                field_name=field,
                original_question=self.static_questions[field],
                answer=answer,
                missing_aspects=missing_aspects,
                conversation_history=""  # Can be enhanced with actual history
            )
        )
        
        return response.content.strip()
    
    async def _generate_interview_brief(self, fields: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é-–±—Ä–∏—Ñ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        with open("src/prompts/interview_brief_generator.txt", "r") as f:
            template = f.read()
        
        prompt = PromptTemplate(
            input_variables=["answers"],
            template=template
        )
        
        # Just pass the fields as they are, let the LLM handle formatting
        response = await self.llm.ainvoke(
            prompt.format(answers=json.dumps(fields, ensure_ascii=False, indent=2))
        )
        
        return response.content
    
    async def _finish_collection(self, message: types.Message, state: FSMContext):
        data = await state.get_data()
        interview_id = data.get("interview_id")
        collected_fields = data.get("collected_fields", {})
        
        try:
            # Generate interview brief
            interview_brief = await self._generate_interview_brief(collected_fields)
            
            # Extract instruction from brief (first message to respondent)
            # Simple extraction - find the section and get the content
            instruction_start = interview_brief.find("### 3. –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç—É")
            if instruction_start != -1:
                instruction_text = interview_brief[instruction_start:]
                instruction_lines = instruction_text.split("\n")[2:]  # Skip header and empty line
                instruction = "\n".join(instruction_lines).strip()
            else:
                # Fallback to generating instruction the old way
                instruction = await self._generate_instruction(collected_fields)
            
            # Update interview
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º researcher_telegram_id –≤ fields –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            collected_fields["researcher_telegram_id"] = message.from_user.id
            
            update_data = {
                "status": "in_progress",
                "fields": collected_fields,
                "researcher_telegram_id": message.from_user.id  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º instruction –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if instruction:
                update_data["instruction"] = instruction
                # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ fields –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                update_data["fields"]["instruction"] = instruction
            
            # –ü–æ–∫–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –ø–æ–ª—è —Ç–æ–ª—å–∫–æ –≤ JSONB fields
            # –ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–π –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
            
            try:
                self.supabase.update_interview(interview_id, update_data)
            except Exception as e:
                logger.error(f"Error updating interview: {e}")
                await message.answer(
                    "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –±—Ä–∏—Ñ–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n"
                    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
                )
                await state.clear()
                return
        
            # Generate interview link
            bot_username = (await message.bot.me()).username
            interview_link = f"https://t.me/{bot_username}?start=interview_{interview_id}"
            
            # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–º–µ–Ω–∏
            researcher_name = collected_fields.get("name", "")
            greeting = f"–û—Ç–ª–∏—á–Ω–æ, {researcher_name}! " if researcher_name else ""
            
            # Send interview brief as a message
            brief_text = (
                f"‚úÖ <b>{greeting}–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ!</b>\n\n"
                f"<b>–°—Å—ã–ª–∫–∞ –¥–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤:</b>\n"
                f"{interview_link}\n\n"
                "üìÑ <b>–ò–Ω—Ç–µ—Ä–≤—å—é-–±—Ä–∏—Ñ:</b>\n\n"
            )
            
            # Send brief in parts to avoid message length limits
            await message.answer(brief_text, reply_markup=types.ReplyKeyboardRemove())
            
            # Send the interview brief
            await message.answer(interview_brief, parse_mode="Markdown")
            
            # Optionally save brief as a file
            # TODO: Implement file generation and sending
            
            await state.clear()
            
        except Exception as e:
            logger.error(f"Error in _finish_collection: {e}", exc_info=True)
            await message.answer(
                "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
            )
            await state.clear()
    
    async def _generate_instruction(self, fields: Dict) -> str:
        with open("src/prompts/instruction_generator.txt", "r") as f:
            template = f.read()
        
        prompt = PromptTemplate(
            input_variables=["fields"],
            template=template
        )
        
        response = await self.llm.ainvoke(prompt.format(fields=fields))
        return response.content
    
    def _is_valid_url(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≤–∞–ª–∏–¥–Ω–æ–π —Å—Å—ã–ª–∫–æ–π"""
        import re
        url_pattern = re.compile(
            r'^https?://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        return bool(url_pattern.match(text.strip()))